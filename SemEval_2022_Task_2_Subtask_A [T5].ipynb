{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9b_p85gxaGc"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook provides a baseline for each setting in [Subtask A of SemEval 2022 Task 2](https://sites.google.com/view/semeval2022task2-idiomaticity#h.qq7eefmehqf9). In addition this provides some helpful pre-processing scripts that you are free to use with your experiments. \n",
        "\n",
        "Please start by stepping through this notebook so you have a clear idea as to what is expected of the task and what you need to submit. \n",
        "\n",
        "These baselines are based on the results described in the paper “[AStitchInLanguageModels: Dataset and Methods for the Exploration of Idiomaticity in Pre-Trained Language Models](https://arxiv.org/abs/2109.04413)”. \n",
        "\n",
        "## Zero-shot setting: Methodology \n",
        "\n",
        "Note that in the zero-shot setting you are NOT allowed to train the model using the one-shot data. \n",
        "\n",
        "In the zero-shot setting, we choose to include the context (the sentences preceding and succeeding the one containing the idioms). We do not add the idiom as an additional feature (in the “second input sentence”). This is based on the results presented in the dataset paper. \n",
        "\n",
        "We use T5 transformer for this setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do-TXGBemGgH"
      },
      "source": [
        "# Setup "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5SL6-fM87rJ",
        "outputId": "f00763df-4ecc-444d-9102-7b64994f3f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 30 11:11:56 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WsITUAnzvFl"
      },
      "source": [
        "Download the Task data and evaluation scripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq3qhQdpl-1-",
        "outputId": "582a8daa-0ddf-4061-a41e-6b045ad52154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SemEval_2022_Task2-idiomaticity'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 123 (delta 48), reused 61 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (123/123), 2.50 MiB | 2.23 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-0POB9tzfNx"
      },
      "source": [
        "Download the “AStitchInLanguageModels” code which we make use of. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "affNQCRktdx4",
        "outputId": "2e11218d-1295-43bd-fd85-f63eb4fc5f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AStitchInLanguageModels'...\n",
            "remote: Enumerating objects: 1030, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 1030 (delta 11), reused 4 (delta 4), pack-reused 1013\u001b[K\n",
            "Receiving objects: 100% (1030/1030), 79.59 MiB | 20.58 MiB/s, done.\n",
            "Resolving deltas: 100% (394/394), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60w-An2vzikk"
      },
      "source": [
        "Download and install an editable version of huggingfaces transformers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8BhcLYcmVvd",
        "outputId": "7b201b7b-1f1c-49f0-d44d-1921da581fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 125165, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 125165 (delta 47), reused 59 (delta 40), pack-reused 125088\n",
            "Receiving objects: 100% (125165/125165), 119.73 MiB | 9.78 MiB/s, done.\n",
            "Resolving deltas: 100% (93942/93942), done.\n",
            "/content/transformers\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.27.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "%cd transformers/\n",
        "!pip install --editable .\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huVMnwTSzmjJ"
      },
      "source": [
        "Required for run_glue ... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tsWits5tw1t",
        "outputId": "55440bbc-3278-4c65-9ca5-0c01b9177781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "## run_glue needs this. \n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-igYdTTgzp9e"
      },
      "source": [
        "Editable install requires runtime restart unless we do this. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOuKplBmmbeB"
      },
      "outputs": [],
      "source": [
        "import site\n",
        "site.main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvC8kAGNnKk_"
      },
      "source": [
        "# Imports and Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZO0WMoYgr_P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import os \n",
        "from pathlib import Path\n",
        "import csv \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzDtW9eXnOhG"
      },
      "outputs": [],
      "source": [
        "def load_csv( path, delimiter=',' ) : \n",
        "  header = None\n",
        "  data   = list()\n",
        "  with open( path, encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader( csvfile, delimiter=delimiter ) \n",
        "    for row in reader : \n",
        "      if header is None : \n",
        "        header = row\n",
        "        continue\n",
        "      data.append( row ) \n",
        "  return header, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwtDsdtAnSZu"
      },
      "outputs": [],
      "source": [
        "def write_csv( data, location ) : \n",
        "  with open( location, 'w', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer( csvfile ) \n",
        "    writer.writerows( data ) \n",
        "  print( \"Wrote {}\".format( location ) ) \n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMH0NFF4jdxq"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Node():\n",
        "  def __init__(self, sentence, label):\n",
        "    self.sentence = sentence\n",
        "    self.label = label\n",
        "\n",
        "def create_idiom_dict_train(data_location, file_name) :\n",
        "    idiom_dict = {}\n",
        "    file_name = os.path.join( data_location, file_name ) \n",
        "    header, data = load_csv( file_name )\n",
        "    for elem in data:\n",
        "        label     = elem[ header.index( 'Label'  ) ]\n",
        "        sentence  = elem[ header.index( 'Target' ) ]\n",
        "        idiom = elem[ header.index( 'MWE' ) ]\n",
        "        if idiom in idiom_dict:\n",
        "          idiom_dict[idiom].append(Node(sentence, label))\n",
        "        else:\n",
        "          idiom_dict[idiom] = [Node(sentence, label)]\n",
        "    return idiom_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW4Hp7w1jfBr"
      },
      "outputs": [],
      "source": [
        "d1 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_zero_shot.csv')\n",
        "d2 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_one_shot.csv')\n",
        "for key, value in d2.items():\n",
        "  if key in d1:\n",
        "    d1[key].append(value)\n",
        "  else:\n",
        "    d1[key] = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Io3D3_z4wt"
      },
      "source": [
        "The following function creates a submission file from the predictions output by run_glue (the text classification script from huggingface transformers - see below). \n",
        "\n",
        "Note that we set it up so we can load up results for only one setting. \n",
        "\n",
        "It requires as input the submission format file, which is available with the data. You can call this after completing each setting to load up results for both settings (see below).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re31vnLoQWww"
      },
      "outputs": [],
      "source": [
        "def insert_to_submission_file( submission_format_file, input_file, prediction_format_file, setting ) :\n",
        "    submission_header, submission_content = load_csv( submission_format_file )\n",
        "    input_header     , input_data         = load_csv( input_file             )\n",
        "    prediction_header, prediction_data    = load_csv( prediction_format_file, '\\t' )\n",
        "\n",
        "    assert len( input_data ) == len( prediction_data )\n",
        "\n",
        "    ## submission_header ['ID', 'Language', 'Setting', 'Label']\n",
        "    ## input_header      ['label', 'sentence1' ]\n",
        "    ## prediction_header ['index', 'prediction']\n",
        "\n",
        "    prediction_data = list( reversed( prediction_data ) )\n",
        "\n",
        "    started_insert  = False\n",
        "    for elem in submission_content : \n",
        "        if elem[ submission_header.index( 'Setting' ) ] != setting :\n",
        "            if started_insert :\n",
        "                if len( prediction_data ) == 0 :\n",
        "                    break\n",
        "                else : \n",
        "                    raise Exception( \"Update should to contiguous ... something wrong.\" ) \n",
        "            continue\n",
        "        started_insert = True\n",
        "        elem[ submission_header.index( 'Label' ) ] = prediction_data.pop()[ prediction_header.index( 'prediction' ) ]\n",
        "\n",
        "    return [ submission_header ] + submission_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44LyZ-OXmgQW"
      },
      "source": [
        "# Pre-process: Create train and dev and evaluation data in required format\n",
        "\n",
        "In the zero-shot setting, we choose to include the context (the sentences preceding and succeeding the one containing the idioms). We do not add the idiom as an additional feature (in the “second input sentence”). \n",
        "\n",
        "In the one shot setting, we train the model on both the zero-shot and one-shot data. In this setting, we exclude the context (the sentences preceding and succeeding the one containing the idioms) and also add the idiom as an additional feature in the “second sentence”. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-3ymBcEmxaV"
      },
      "source": [
        "## Functions for pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MthVK7EQm6m_"
      },
      "source": [
        "### _get_train_data\n",
        "\n",
        "This function generates training data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r15lgixFWSRI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def _get_train_data( data_location, file_name, include_context, include_idiom ) :\n",
        "    \n",
        "    file_name = os.path.join( data_location, file_name ) \n",
        "\n",
        "    header, data = load_csv( file_name )\n",
        "\n",
        "    out_header = [ 'label', 'sentence1' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
        "        \n",
        "    # ['DataID', 'Language', 'MWE', 'Setting', 'Previous', 'Target', 'Next', 'Label']\n",
        "    out_data = list()\n",
        "    for elem in data :\n",
        "        label     = elem[ header.index( 'Label'  ) ]\n",
        "        sentence1 = elem[ header.index( 'Target' ) ]\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ header.index( 'Previous' ) ], elem[ header.index( 'Target' ) ], elem[ header.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ] \n",
        "        else :\n",
        "            sentence2 = elem[ header.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        out_data.append( this_row )\n",
        "        assert len( out_header ) == len( this_row )\n",
        "    return [ out_header ] + out_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cytociCB3WZM"
      },
      "source": [
        "### _get_dev_eval_data\n",
        "\n",
        "This function generates training dev and eval data in the format required by the huggingface’s example script. It will include and exclude the MWE and the context based on parameters. \n",
        "\n",
        "Additionally, if there is no gold label provides (as in the case of eval) it will generate a file that can be used to generate predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXQ4JXkaWh8H"
      },
      "outputs": [],
      "source": [
        "def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n",
        "\n",
        "    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n",
        "    gold_header  = gold_data = None\n",
        "    if not gold_file_name is None : \n",
        "        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n",
        "        assert len( input_data ) == len( gold_data )\n",
        "\n",
        "    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n",
        "    # ['ID', 'DataID', 'Language', 'Label']\n",
        "    \n",
        "    out_header = [ 'label', 'sentence1' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
        "\n",
        "    out_data = list()\n",
        "    for index in range( len( input_data ) ) :\n",
        "        label = 1\n",
        "        if not gold_file_name is None : \n",
        "            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n",
        "            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n",
        "            assert this_input_id == this_gold_id\n",
        "            \n",
        "            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n",
        "            \n",
        "        elem      = input_data[ index ]\n",
        "        sentence1 = elem[ input_headers.index( 'Target' ) ]\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ] \n",
        "        else :\n",
        "            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        assert len( out_header ) == len( this_row ) \n",
        "        out_data.append( this_row )\n",
        "        \n",
        "\n",
        "    return [ out_header ] + out_data\n",
        "\n",
        "def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n",
        "\n",
        "    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n",
        "    gold_header  = gold_data = None\n",
        "    if not gold_file_name is None : \n",
        "        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n",
        "        assert len( input_data ) == len( gold_data )\n",
        "\n",
        "    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n",
        "    # ['ID', 'DataID', 'Language', 'Label']\n",
        "    \n",
        "    out_header = [ 'label', 'sentence1' ]\n",
        "    if include_idiom :\n",
        "        out_header = [ 'label', 'sentence1', 'sentence2' ]\n",
        "\n",
        "    out_data = list()\n",
        "    for index in range( len( input_data ) ) :\n",
        "        label = 1\n",
        "        if not gold_file_name is None : \n",
        "            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n",
        "            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n",
        "            assert this_input_id == this_gold_id\n",
        "            \n",
        "            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n",
        "            \n",
        "        elem      = input_data[ index ]\n",
        "        sentence1 = elem[ input_headers.index( 'Target' ) ]\n",
        "        if include_context :\n",
        "            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n",
        "        this_row = None\n",
        "        if not include_idiom :\n",
        "            this_row = [ label, sentence1 ] \n",
        "        else :\n",
        "            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n",
        "            this_row = [ label, sentence1, sentence2 ]\n",
        "        assert len( out_header ) == len( this_row ) \n",
        "        out_data.append( this_row )\n",
        "        \n",
        "\n",
        "    return [ out_header ] + out_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjIbyTnn3fHP"
      },
      "source": [
        "### create_data\n",
        "\n",
        "This function generates the training, development and evaluation data. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1tr-zNvnBCV"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Based on the results presented in `AStitchInLanguageModels' we work with not including the idiom for the zero shot setting and including it in the one shot setting.\n",
        "\"\"\"\n",
        "def create_data( input_location, output_location ) :\n",
        "\n",
        "    \n",
        "    ## Zero shot data\n",
        "    train_data = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = True,\n",
        "        include_idiom   = False\n",
        "    )\n",
        "    write_csv( train_data, os.path.join( output_location, 'ZeroShot', 'train.csv' ) )\n",
        "    \n",
        "    dev_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'dev.csv',\n",
        "        gold_file_name   = 'dev_gold.csv', \n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )        \n",
        "    write_csv( dev_data, os.path.join( output_location, 'ZeroShot', 'dev.csv' ) )\n",
        "    \n",
        "    eval_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'eval.csv',\n",
        "        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n",
        "        include_context  = True,\n",
        "        include_idiom    = False\n",
        "    )\n",
        "    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n",
        "\n",
        "\n",
        "    ## OneShot Data (combine both for training)\n",
        "    train_zero_data = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_zero_shot.csv',\n",
        "        include_context = False,\n",
        "        include_idiom   = True\n",
        "    )\n",
        "    train_one_data = _get_train_data(\n",
        "        data_location   = input_location,\n",
        "        file_name       = 'train_one_shot.csv',\n",
        "        include_context = False,\n",
        "        include_idiom   = True\n",
        "    )\n",
        "\n",
        "    assert train_zero_data[0] == train_one_data[0] ## Headers\n",
        "    train_data = train_one_data + train_zero_data[1:]\n",
        "    write_csv( train_data, os.path.join( output_location, 'OneShot', 'train.csv' ) )\n",
        "    \n",
        "    dev_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'dev.csv',\n",
        "        gold_file_name   = 'dev_gold.csv', \n",
        "        include_context  = False,\n",
        "        include_idiom    = True\n",
        "    )        \n",
        "    write_csv( dev_data, os.path.join( output_location, 'OneShot', 'dev.csv' ) )\n",
        "    \n",
        "    eval_data = _get_dev_eval_data(\n",
        "        data_location    = input_location,\n",
        "        input_file_name  = 'eval.csv',\n",
        "        gold_file_name   = None,\n",
        "        include_context  = False,\n",
        "        include_idiom    = True\n",
        "    )\n",
        "    write_csv( eval_data, os.path.join( output_location, 'OneShot', 'eval.csv' ) )\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmQfvym8ndKH"
      },
      "source": [
        "## Setup and Create data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxCgaHlKnpMR",
        "outputId": "714484cb-0c7c-4cf0-a339-a57d271f6085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AStitchInLanguageModels  sample_data\t\t\t  transformers\n",
            "Data\t\t\t SemEval_2022_Task2-idiomaticity\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IFlXMzwL48U"
      },
      "source": [
        "##Explotary data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuWdyx8Y1KWu"
      },
      "source": [
        "train_zero_shot.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL5LUxYPLeGA"
      },
      "outputs": [],
      "source": [
        "directory   = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/'\n",
        "zero_shot_tr = os.path.join(directory, 'train_zero_shot.csv')\n",
        "one_shot_tr = os.path.join(directory, 'train_one_shot.csv')\n",
        "dev = os.path.join(directory, 'dev.csv')\n",
        "dev_gold = os.path.join(directory, 'dev_gold.csv')\n",
        "\n",
        "df_z_s = pd.read_csv(zero_shot_tr)\n",
        "df_o_s= pd.read_csv(one_shot_tr)\n",
        "df_dev = pd.read_csv(dev)\n",
        "df_dev_gold= pd.read_csv(dev_gold)\n",
        "df_dev= df_dev.merge(df_dev_gold, validate='one_to_one')\n",
        "dfs = {'Zero Shot Data': df_z_s}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pfwwdtUYLfE4",
        "outputId": "f2406757-1391-40fc-8562-6cfa9b935d5d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                         DataID Language           MWE    Setting  \\\n",
              "0      train_zero_shot.EN.168.1       EN  double dutch  zero_shot   \n",
              "1      train_zero_shot.EN.168.2       EN  double dutch  zero_shot   \n",
              "2      train_zero_shot.EN.168.3       EN  double dutch  zero_shot   \n",
              "3      train_zero_shot.EN.168.4       EN  double dutch  zero_shot   \n",
              "4      train_zero_shot.EN.168.5       EN  double dutch  zero_shot   \n",
              "...                         ...      ...           ...        ...   \n",
              "4486   train_zero_shot.PT.351.8       PT  gato-pingado  zero_shot   \n",
              "4487   train_zero_shot.PT.351.9       PT  gato-pingado  zero_shot   \n",
              "4488  train_zero_shot.PT.351.10       PT  gato-pingado  zero_shot   \n",
              "4489  train_zero_shot.PT.351.11       PT  gato-pingado  zero_shot   \n",
              "4490  train_zero_shot.PT.351.12       PT  gato-pingado  zero_shot   \n",
              "\n",
              "                                               Previous  \\\n",
              "0     This inspired others to jump ropes as a leisur...   \n",
              "1     In the age of chivalry a man paid for the woma...   \n",
              "2     To her eternal credit, she kept both India and...   \n",
              "3     While pharmaceutical companies were researchin...   \n",
              "4     Coronavirus in Europe   * Brexit   * Brussels ...   \n",
              "...                                                 ...   \n",
              "4486                                 Era o ano de 1968.   \n",
              "4487  De acordo com informações vazadas de dentro da...   \n",
              "4488  O radialista Roberto Toledo apresentou o show ...   \n",
              "4489  O carnaval em Goiânia também tem espaço para o...   \n",
              "4490  A concentração aconteceu na Avenida Circular, ...   \n",
              "\n",
              "                                                 Target  \\\n",
              "0     There are several theories behind the origin o...   \n",
              "1     Double Dutch also derives from the same era, D...   \n",
              "2     Since 1977 we have had a plethora of Foreign M...   \n",
              "3     Turns out that these people were speaking doub...   \n",
              "4              Is Flemish premier talking double Dutch?   \n",
              "...                                                 ...   \n",
              "4486   A estação de passageiros tranquila, com um ou...   \n",
              "4487  Segundo a fonte, o programa vai seguir um form...   \n",
              "4488  \"Eu fiquei sentado no chão e realmente só tinh...   \n",
              "4489  É o caso do bloco “Gato Pingado”, que reuniu c...   \n",
              "4490  De acordo com presidente do bloco, Paulo de Tá...   \n",
              "\n",
              "                                                   Next  Label  \n",
              "0     The most popular theory states that “Double Du...      0  \n",
              "1     There are many phrases that include the word: ...      0  \n",
              "2     We need to exclude from that list the late Mr ...      0  \n",
              "3     So why aren’t Big Macs sold all over the world...      0  \n",
              "4     Three months before the Belgians take over the...      0  \n",
              "...                                                 ...    ...  \n",
              "4486  Com os primeiros raios solares, o potente DC 8...      0  \n",
              "4487  Leonardo fica inchado, perde a voz e vício mor...      0  \n",
              "4488  Entre os poucos espectadores estava o advogado...      0  \n",
              "4489  Segundo os organizadores, quando criaram o blo...      1  \n",
              "4490   “A diferença do bloco é que realmente é um ca...      1  \n",
              "\n",
              "[4491 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eed4a336-08b2-4c7c-b493-effb088e6177\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DataID</th>\n",
              "      <th>Language</th>\n",
              "      <th>MWE</th>\n",
              "      <th>Setting</th>\n",
              "      <th>Previous</th>\n",
              "      <th>Target</th>\n",
              "      <th>Next</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_zero_shot.EN.168.1</td>\n",
              "      <td>EN</td>\n",
              "      <td>double dutch</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>This inspired others to jump ropes as a leisur...</td>\n",
              "      <td>There are several theories behind the origin o...</td>\n",
              "      <td>The most popular theory states that “Double Du...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_zero_shot.EN.168.2</td>\n",
              "      <td>EN</td>\n",
              "      <td>double dutch</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>In the age of chivalry a man paid for the woma...</td>\n",
              "      <td>Double Dutch also derives from the same era, D...</td>\n",
              "      <td>There are many phrases that include the word: ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_zero_shot.EN.168.3</td>\n",
              "      <td>EN</td>\n",
              "      <td>double dutch</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>To her eternal credit, she kept both India and...</td>\n",
              "      <td>Since 1977 we have had a plethora of Foreign M...</td>\n",
              "      <td>We need to exclude from that list the late Mr ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_zero_shot.EN.168.4</td>\n",
              "      <td>EN</td>\n",
              "      <td>double dutch</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>While pharmaceutical companies were researchin...</td>\n",
              "      <td>Turns out that these people were speaking doub...</td>\n",
              "      <td>So why aren’t Big Macs sold all over the world...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_zero_shot.EN.168.5</td>\n",
              "      <td>EN</td>\n",
              "      <td>double dutch</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>Coronavirus in Europe   * Brexit   * Brussels ...</td>\n",
              "      <td>Is Flemish premier talking double Dutch?</td>\n",
              "      <td>Three months before the Belgians take over the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4486</th>\n",
              "      <td>train_zero_shot.PT.351.8</td>\n",
              "      <td>PT</td>\n",
              "      <td>gato-pingado</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>Era o ano de 1968.</td>\n",
              "      <td>A estação de passageiros tranquila, com um ou...</td>\n",
              "      <td>Com os primeiros raios solares, o potente DC 8...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4487</th>\n",
              "      <td>train_zero_shot.PT.351.9</td>\n",
              "      <td>PT</td>\n",
              "      <td>gato-pingado</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>De acordo com informações vazadas de dentro da...</td>\n",
              "      <td>Segundo a fonte, o programa vai seguir um form...</td>\n",
              "      <td>Leonardo fica inchado, perde a voz e vício mor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4488</th>\n",
              "      <td>train_zero_shot.PT.351.10</td>\n",
              "      <td>PT</td>\n",
              "      <td>gato-pingado</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>O radialista Roberto Toledo apresentou o show ...</td>\n",
              "      <td>\"Eu fiquei sentado no chão e realmente só tinh...</td>\n",
              "      <td>Entre os poucos espectadores estava o advogado...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4489</th>\n",
              "      <td>train_zero_shot.PT.351.11</td>\n",
              "      <td>PT</td>\n",
              "      <td>gato-pingado</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>O carnaval em Goiânia também tem espaço para o...</td>\n",
              "      <td>É o caso do bloco “Gato Pingado”, que reuniu c...</td>\n",
              "      <td>Segundo os organizadores, quando criaram o blo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4490</th>\n",
              "      <td>train_zero_shot.PT.351.12</td>\n",
              "      <td>PT</td>\n",
              "      <td>gato-pingado</td>\n",
              "      <td>zero_shot</td>\n",
              "      <td>A concentração aconteceu na Avenida Circular, ...</td>\n",
              "      <td>De acordo com presidente do bloco, Paulo de Tá...</td>\n",
              "      <td>“A diferença do bloco é que realmente é um ca...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4491 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eed4a336-08b2-4c7c-b493-effb088e6177')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eed4a336-08b2-4c7c-b493-effb088e6177 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eed4a336-08b2-4c7c-b493-effb088e6177');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_z_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yvfLJWtZOit5",
        "outputId": "4108cbd0-29f8-4eb0-d975-714ea460db13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        ID Language              MWE  \\\n",
              "0     3652       EN        high life   \n",
              "1    11103       EN        high life   \n",
              "2    84346       EN        high life   \n",
              "3    56279       EN        high life   \n",
              "4    17886       EN        high life   \n",
              "..     ...      ...              ...   \n",
              "734  95336       PT  papel higiênico   \n",
              "735  20353       PT  papel higiênico   \n",
              "736  54479       PT  papel higiênico   \n",
              "737  85941       PT  papel higiênico   \n",
              "738  13078       PT  papel higiênico   \n",
              "\n",
              "                                              Previous  \\\n",
              "0    Does the plumbing predictably rebel, creating ...   \n",
              "1    Let’s be honest – we would be chuffed if our b...   \n",
              "2                   I already have the winning ticket.   \n",
              "3    There were signs everywhere of cosy, comfortab...   \n",
              "4                              Yet one thing is clear.   \n",
              "..                                                 ...   \n",
              "734  O presidente da Suzano Papel e Celulose, Walte...   \n",
              "735  Atualmente, poderiam surgir problemas com carg...   \n",
              "736  Policiais penais do Complexo Penitenciário Dr ...   \n",
              "737  O acidente ocorreu depois de fortes rajadas de...   \n",
              "738  Um incêndio atingiu um caminhão na noite desta...   \n",
              "\n",
              "                                                Target  \\\n",
              "0    Are these interruptions of the good life a nec...   \n",
              "1    But for Australian fashion designer Abby Kheir...   \n",
              "2    With that, I will be enjoying the pleasures of...   \n",
              "3    Fendi offered swaddling, belted coats resembli...   \n",
              "4    Rick Ross and Diddy exemplify the high life, t...   \n",
              "..                                                 ...   \n",
              "734  A Suzano Papel e Celulose é uma das 10 maiores...   \n",
              "735  O presidente da Suzano Papel e Celulose, Walte...   \n",
              "736  O material entorpecente estava escondido em ro...   \n",
              "737  No caso do papel higiênico, a escassez de cont...   \n",
              "738  Segundo as informações, o veículo transportava...   \n",
              "\n",
              "                                                  Next        DataID  Label  \n",
              "0    Not at all , says James von Klemperer, preside...  dev.EN.147.1      1  \n",
              "1    Speaking to the Daily Mail , the owner of Abys...  dev.EN.147.2      1  \n",
              "2    Charles Selle is a former News-Sun reporter, p...  dev.EN.147.3      1  \n",
              "3    Shawl collars and enveloping dressing-gown sty...  dev.EN.147.4      1  \n",
              "4    And who knows -- maybe we'll see Puff on his a...  dev.EN.147.5      1  \n",
              "..                                                 ...           ...    ...  \n",
              "734  Vale destacar que a Suzano já recebeu menos en...  dev.PT.394.4      1  \n",
              "735  A Suzano Papel e Celulose é uma das 10 maiores...  dev.PT.394.5      1  \n",
              "736  O flagrante ocorreu na manhã desta sexta-feira...  dev.PT.394.6      1  \n",
              "737  Schalka, da Suzano, teme que os problemas logí...  dev.PT.394.7      1  \n",
              "738  O Corpo de Bombeiros fez o combate ao fogo e c...  dev.PT.394.8      1  \n",
              "\n",
              "[739 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4b9ca80-271c-4fc5-a123-5334d2dd1045\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Language</th>\n",
              "      <th>MWE</th>\n",
              "      <th>Previous</th>\n",
              "      <th>Target</th>\n",
              "      <th>Next</th>\n",
              "      <th>DataID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3652</td>\n",
              "      <td>EN</td>\n",
              "      <td>high life</td>\n",
              "      <td>Does the plumbing predictably rebel, creating ...</td>\n",
              "      <td>Are these interruptions of the good life a nec...</td>\n",
              "      <td>Not at all , says James von Klemperer, preside...</td>\n",
              "      <td>dev.EN.147.1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11103</td>\n",
              "      <td>EN</td>\n",
              "      <td>high life</td>\n",
              "      <td>Let’s be honest – we would be chuffed if our b...</td>\n",
              "      <td>But for Australian fashion designer Abby Kheir...</td>\n",
              "      <td>Speaking to the Daily Mail , the owner of Abys...</td>\n",
              "      <td>dev.EN.147.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84346</td>\n",
              "      <td>EN</td>\n",
              "      <td>high life</td>\n",
              "      <td>I already have the winning ticket.</td>\n",
              "      <td>With that, I will be enjoying the pleasures of...</td>\n",
              "      <td>Charles Selle is a former News-Sun reporter, p...</td>\n",
              "      <td>dev.EN.147.3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56279</td>\n",
              "      <td>EN</td>\n",
              "      <td>high life</td>\n",
              "      <td>There were signs everywhere of cosy, comfortab...</td>\n",
              "      <td>Fendi offered swaddling, belted coats resembli...</td>\n",
              "      <td>Shawl collars and enveloping dressing-gown sty...</td>\n",
              "      <td>dev.EN.147.4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17886</td>\n",
              "      <td>EN</td>\n",
              "      <td>high life</td>\n",
              "      <td>Yet one thing is clear.</td>\n",
              "      <td>Rick Ross and Diddy exemplify the high life, t...</td>\n",
              "      <td>And who knows -- maybe we'll see Puff on his a...</td>\n",
              "      <td>dev.EN.147.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>95336</td>\n",
              "      <td>PT</td>\n",
              "      <td>papel higiênico</td>\n",
              "      <td>O presidente da Suzano Papel e Celulose, Walte...</td>\n",
              "      <td>A Suzano Papel e Celulose é uma das 10 maiores...</td>\n",
              "      <td>Vale destacar que a Suzano já recebeu menos en...</td>\n",
              "      <td>dev.PT.394.4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>20353</td>\n",
              "      <td>PT</td>\n",
              "      <td>papel higiênico</td>\n",
              "      <td>Atualmente, poderiam surgir problemas com carg...</td>\n",
              "      <td>O presidente da Suzano Papel e Celulose, Walte...</td>\n",
              "      <td>A Suzano Papel e Celulose é uma das 10 maiores...</td>\n",
              "      <td>dev.PT.394.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>54479</td>\n",
              "      <td>PT</td>\n",
              "      <td>papel higiênico</td>\n",
              "      <td>Policiais penais do Complexo Penitenciário Dr ...</td>\n",
              "      <td>O material entorpecente estava escondido em ro...</td>\n",
              "      <td>O flagrante ocorreu na manhã desta sexta-feira...</td>\n",
              "      <td>dev.PT.394.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>85941</td>\n",
              "      <td>PT</td>\n",
              "      <td>papel higiênico</td>\n",
              "      <td>O acidente ocorreu depois de fortes rajadas de...</td>\n",
              "      <td>No caso do papel higiênico, a escassez de cont...</td>\n",
              "      <td>Schalka, da Suzano, teme que os problemas logí...</td>\n",
              "      <td>dev.PT.394.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>13078</td>\n",
              "      <td>PT</td>\n",
              "      <td>papel higiênico</td>\n",
              "      <td>Um incêndio atingiu um caminhão na noite desta...</td>\n",
              "      <td>Segundo as informações, o veículo transportava...</td>\n",
              "      <td>O Corpo de Bombeiros fez o combate ao fogo e c...</td>\n",
              "      <td>dev.PT.394.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>739 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4b9ca80-271c-4fc5-a123-5334d2dd1045')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4b9ca80-271c-4fc5-a123-5334d2dd1045 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4b9ca80-271c-4fc5-a123-5334d2dd1045');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Ee8UIwTbPnnE",
        "outputId": "93b17f19-3d1f-434d-e9e2-b83bf95ee56e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        ID        DataID Language  Label\n",
              "0     3652  dev.EN.147.1       EN      1\n",
              "1    11103  dev.EN.147.2       EN      1\n",
              "2    84346  dev.EN.147.3       EN      1\n",
              "3    56279  dev.EN.147.4       EN      1\n",
              "4    17886  dev.EN.147.5       EN      1\n",
              "..     ...           ...      ...    ...\n",
              "734  95336  dev.PT.394.4       PT      1\n",
              "735  20353  dev.PT.394.5       PT      1\n",
              "736  54479  dev.PT.394.6       PT      1\n",
              "737  85941  dev.PT.394.7       PT      1\n",
              "738  13078  dev.PT.394.8       PT      1\n",
              "\n",
              "[739 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c05e3c2-ed4f-4f4d-85f2-6f5c706bb3c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>DataID</th>\n",
              "      <th>Language</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3652</td>\n",
              "      <td>dev.EN.147.1</td>\n",
              "      <td>EN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11103</td>\n",
              "      <td>dev.EN.147.2</td>\n",
              "      <td>EN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84346</td>\n",
              "      <td>dev.EN.147.3</td>\n",
              "      <td>EN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56279</td>\n",
              "      <td>dev.EN.147.4</td>\n",
              "      <td>EN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17886</td>\n",
              "      <td>dev.EN.147.5</td>\n",
              "      <td>EN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>95336</td>\n",
              "      <td>dev.PT.394.4</td>\n",
              "      <td>PT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>735</th>\n",
              "      <td>20353</td>\n",
              "      <td>dev.PT.394.5</td>\n",
              "      <td>PT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>54479</td>\n",
              "      <td>dev.PT.394.6</td>\n",
              "      <td>PT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>737</th>\n",
              "      <td>85941</td>\n",
              "      <td>dev.PT.394.7</td>\n",
              "      <td>PT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>738</th>\n",
              "      <td>13078</td>\n",
              "      <td>dev.PT.394.8</td>\n",
              "      <td>PT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>739 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c05e3c2-ed4f-4f4d-85f2-6f5c706bb3c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c05e3c2-ed4f-4f4d-85f2-6f5c706bb3c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c05e3c2-ed4f-4f4d-85f2-6f5c706bb3c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_dev_gold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBHtvhrHLlpz",
        "outputId": "9eb5eb4c-dd73-487e-de0e-6b0127a4ce54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "############# Zero Shot Data #############\n",
            "\n",
            "Total Samples: 4491\n",
            "\n",
            "EN    3327\n",
            "PT    1164\n",
            "Name: Language, dtype: int64\n",
            "Number of Languages: 2\n",
            "\n",
            "0    2535\n",
            "1    1956\n",
            "Name: Label, dtype: int64\n",
            "Number of Labels: 2\n",
            "\n",
            "information age     34\n",
            "brass ring          32\n",
            "peace talk          31\n",
            "ônibus executivo     9\n",
            "double dutch         9\n",
            "algodão-doce         6\n",
            "Name: MWE, dtype: int64\n",
            "Number of MWEs: 236\n"
          ]
        }
      ],
      "source": [
        "for key, df in dfs.items():\n",
        "    print(\"\\n\"+\"#\"*((40 - len(key))//2)+\" {} \".format(key)+\"#\"*((40 - len(key))//2))\n",
        "    print(\"\\nTotal Samples: {}\".format(len(df)))\n",
        "    for col in [\"Language\", \"Label\", \"MWE\"]:\n",
        "        value_counts = df[col].value_counts()\n",
        "        unique_values = len(value_counts)\n",
        "        if len(value_counts) > 5:\n",
        "            print(\"\\n{}\".format(value_counts.iloc[:3].append(value_counts[-3:])))\n",
        "        else:\n",
        "            print(\"\\n{}\".format(value_counts))\n",
        "        print(\"Number of {}s: {}\".format(col, unique_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6mebjjVLrJJ",
        "outputId": "e3dbc2f3-919b-486d-ae61-940bba685f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of English MWEs in zero shot data: 163\n",
            "Number of Portuguese MWEs in zero shot data: 73\n"
          ]
        }
      ],
      "source": [
        "zero_shot_unique_eng_mwes = len(set(df_z_s[df_z_s[\"Language\"] == 'EN'][\"MWE\"]))\n",
        "zero_shot_unique_pt_mwes = len(set(df_z_s[df_z_s[\"Language\"] == 'PT'][\"MWE\"]))\n",
        "print(\"Number of English MWEs in zero shot data: {}\".format(zero_shot_unique_eng_mwes))\n",
        "print(\"Number of Portuguese MWEs in zero shot data: {}\".format(zero_shot_unique_pt_mwes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM6-i-bzLzFW",
        "outputId": "5e1dddc5-dde5-4d20-820e-7fc3d09e07bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of common MWEs in zero and one shot data: 0\n",
            "Number of common MWEs in zero shot and dev data: 0\n",
            "Number of common MWEs in one shot and dev data: 50\n"
          ]
        }
      ],
      "source": [
        "common_zero_one = set(df_z_s['MWE']) & set(df_o_s['MWE'])\n",
        "common_zero_dev = set(df_z_s['MWE']) & set(df_dev['MWE'])\n",
        "common_one_dev = set(df_o_s['MWE']) & set(df_dev['MWE'])\n",
        "print(\"Number of common MWEs in zero and one shot data: {}\".format(len(common_zero_one)))\n",
        "print(\"Number of common MWEs in zero shot and dev data: {}\".format(len(common_zero_dev)))\n",
        "print(\"Number of common MWEs in one shot and dev data: {}\".format(len(common_one_dev)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outpath = 'Data'\n",
        "    \n",
        "Path( os.path.join( outpath, 'ZeroShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "Path( os.path.join( outpath, 'OneShot' ) ).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "create_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', outpath )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn2q_VBPZyy_",
        "outputId": "505a35d8-f928-4982-ccac-f196318cee51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote Data/ZeroShot/train.csv\n",
            "Wrote Data/ZeroShot/dev.csv\n",
            "Wrote Data/ZeroShot/eval.csv\n",
            "Wrote Data/OneShot/train.csv\n",
            "Wrote Data/OneShot/dev.csv\n",
            "Wrote Data/OneShot/eval.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1Xmw0911Cvz"
      },
      "source": [
        "Load train.csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3v7HqoxnrOr"
      },
      "outputs": [],
      "source": [
        "directory   = '/content/Data/ZeroShot'\n",
        "zs_tr = os.path.join(directory, 'train.csv')\n",
        "\n",
        "df_zs = pd.read_csv(zs_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "mBIVrIUGrgny",
        "outputId": "5cfbb1dd-4186-4eec-98b0-3a96183d52e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      label                                          sentence1\n",
              "0         0  This inspired others to jump ropes as a leisur...\n",
              "1         0  In the age of chivalry a man paid for the woma...\n",
              "2         0  To her eternal credit, she kept both India and...\n",
              "3         0  While pharmaceutical companies were researchin...\n",
              "4         0  Coronavirus in Europe   * Brexit   * Brussels ...\n",
              "...     ...                                                ...\n",
              "4486      0  Era o ano de 1968.  A estação de passageiros t...\n",
              "4487      0  De acordo com informações vazadas de dentro da...\n",
              "4488      0  O radialista Roberto Toledo apresentou o show ...\n",
              "4489      1  O carnaval em Goiânia também tem espaço para o...\n",
              "4490      1  A concentração aconteceu na Avenida Circular, ...\n",
              "\n",
              "[4491 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c94cd4e-009f-4f04-ab79-ffe8533a3013\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>This inspired others to jump ropes as a leisur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>In the age of chivalry a man paid for the woma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>To her eternal credit, she kept both India and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>While pharmaceutical companies were researchin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Coronavirus in Europe   * Brexit   * Brussels ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4486</th>\n",
              "      <td>0</td>\n",
              "      <td>Era o ano de 1968.  A estação de passageiros t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4487</th>\n",
              "      <td>0</td>\n",
              "      <td>De acordo com informações vazadas de dentro da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4488</th>\n",
              "      <td>0</td>\n",
              "      <td>O radialista Roberto Toledo apresentou o show ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4489</th>\n",
              "      <td>1</td>\n",
              "      <td>O carnaval em Goiânia também tem espaço para o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4490</th>\n",
              "      <td>1</td>\n",
              "      <td>A concentração aconteceu na Avenida Circular, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4491 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c94cd4e-009f-4f04-ab79-ffe8533a3013')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c94cd4e-009f-4f04-ab79-ffe8533a3013 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c94cd4e-009f-4f04-ab79-ffe8533a3013');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_zs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7UAKqXlzARS"
      },
      "source": [
        "#Dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqewhgSu0Ihk"
      },
      "outputs": [],
      "source": [
        "#Removing columns which are not required\n",
        "data = df_z_s.drop([\"DataID\", \"Language\", \"Setting\", \"Previous\", \"Next\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "ppxIyLxI1onc",
        "outputId": "c4bf5d23-11f4-4bba-b6c1-33d11fcc5401"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            MWE                                             Target  Label\n",
              "0  double dutch  There are several theories behind the origin o...      0\n",
              "1  double dutch  Double Dutch also derives from the same era, D...      0\n",
              "2  double dutch  Since 1977 we have had a plethora of Foreign M...      0\n",
              "3  double dutch  Turns out that these people were speaking doub...      0\n",
              "4  double dutch           Is Flemish premier talking double Dutch?      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7716c649-f7c9-4129-abb1-f16110269dbb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MWE</th>\n",
              "      <th>Target</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>double dutch</td>\n",
              "      <td>There are several theories behind the origin o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>double dutch</td>\n",
              "      <td>Double Dutch also derives from the same era, D...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>double dutch</td>\n",
              "      <td>Since 1977 we have had a plethora of Foreign M...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>double dutch</td>\n",
              "      <td>Turns out that these people were speaking doub...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>double dutch</td>\n",
              "      <td>Is Flemish premier talking double Dutch?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7716c649-f7c9-4129-abb1-f16110269dbb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7716c649-f7c9-4129-abb1-f16110269dbb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7716c649-f7c9-4129-abb1-f16110269dbb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYgXul91118n",
        "outputId": "a71dff69-ce64-4220-c4b6-34ec8f35b22a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MWE       0\n",
              "Target    0\n",
              "Label     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ej0hnkp17Cc"
      },
      "source": [
        "Randomly shuffling the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNqEFtGP13Ar"
      },
      "outputs": [],
      "source": [
        "data = data.sample(frac = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "wJAxNCWa2JAx",
        "outputId": "1b35d1a4-074a-450d-c6d1-492855fce80c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                MWE                                             Target  Label\n",
              "2497  academy award  Cloris Leachman, who won eight Emmy Awards and...      1\n",
              "3994  café colonial  Alguns ficaram dentro do imóvel, outros do lad...      0\n",
              "0      double dutch  There are several theories behind the origin o...      0\n",
              "2774   couch potato           But for one lucky couch potato, it will.      0\n",
              "1115  swimming pool  To ascertain that such a situation doesn’t ari...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0329c1ec-7757-48ba-97f8-c39cd7a865c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MWE</th>\n",
              "      <th>Target</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>academy award</td>\n",
              "      <td>Cloris Leachman, who won eight Emmy Awards and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3994</th>\n",
              "      <td>café colonial</td>\n",
              "      <td>Alguns ficaram dentro do imóvel, outros do lad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>double dutch</td>\n",
              "      <td>There are several theories behind the origin o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>couch potato</td>\n",
              "      <td>But for one lucky couch potato, it will.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>swimming pool</td>\n",
              "      <td>To ascertain that such a situation doesn’t ari...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0329c1ec-7757-48ba-97f8-c39cd7a865c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0329c1ec-7757-48ba-97f8-c39cd7a865c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0329c1ec-7757-48ba-97f8-c39cd7a865c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCisc_E72iYf"
      },
      "source": [
        "##Creating a function to convert the text in lowercase, remove the extra space, special chr., ulr and links."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNwL7Tyi4cq8"
      },
      "source": [
        "For target sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLVtdg9a2Ylt"
      },
      "outputs": [],
      "source": [
        "def wordopt(Target):\n",
        "    text = Target.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', Target)\n",
        "    text = re.sub(\"\\\\W\",\" \",Target)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', Target)\n",
        "    text = re.sub('<.*?>+', '', Target)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', Target)\n",
        "    text = re.sub('\\n', '', Target)\n",
        "    text = re.sub('\\w*\\d\\w*', '', Target)    \n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vIAe8dJ2dcd"
      },
      "outputs": [],
      "source": [
        "data[\"Target\"] = data[\"Target\"].apply(wordopt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpQlULahJMaD"
      },
      "source": [
        "##Merge target and MWE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6SXupIBJL6G",
        "outputId": "9c9520e4-7e0a-4340-cb30-027599ec86d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    MWE                                             Target  \\\n",
            "2497      academy award  Cloris Leachman, who won eight Emmy Awards and...   \n",
            "3994      café colonial  Alguns ficaram dentro do imóvel, outros do lad...   \n",
            "0          double dutch  There are several theories behind the origin o...   \n",
            "2774       couch potato           But for one lucky couch potato, it will.   \n",
            "1115      swimming pool  To ascertain that such a situation doesn’t ari...   \n",
            "...                 ...                                                ...   \n",
            "1982   social insurance  Simply put, can we imagine the U.S. Congress s...   \n",
            "1362         brass ring  Hosting on Fox News is the brass ring for talent.   \n",
            "404         melting pot  The historic neighborhood was once a bustling ...   \n",
            "2020         box office  He said the film will also be remembered as tu...   \n",
            "692   grandfather clock  Stewart's flair for drama gives some of the al...   \n",
            "\n",
            "      Label                                               text  \n",
            "2497      1  academy awardCloris Leachman, who won eight Em...  \n",
            "3994      0  café colonialAlguns ficaram dentro do imóvel, ...  \n",
            "0         0  double dutchThere are several theories behind ...  \n",
            "2774      0  couch potatoBut for one lucky couch potato, it...  \n",
            "1115      1  swimming poolTo ascertain that such a situatio...  \n",
            "...     ...                                                ...  \n",
            "1982      1  social insuranceSimply put, can we imagine the...  \n",
            "1362      0  brass ringHosting on Fox News is the brass rin...  \n",
            "404       0  melting potThe historic neighborhood was once ...  \n",
            "2020      0  box officeHe said the film will also be rememb...  \n",
            "692       0  grandfather clockStewart's flair for drama giv...  \n",
            "\n",
            "[4491 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# Merge columns using the \"merge\" function\n",
        "data[\"text\"] = data[\"MWE\"].map(str) + data[\"Target\"].map(str)\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687
        },
        "id": "EOOM9nv8M83B",
        "outputId": "febb9887-6a40-440f-b390-439bc327a577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                MWE                                             Target  Label  \\\n",
              "2497  academy award  Cloris Leachman, who won eight Emmy Awards and...      1   \n",
              "3994  café colonial  Alguns ficaram dentro do imóvel, outros do lad...      0   \n",
              "0      double dutch  There are several theories behind the origin o...      0   \n",
              "2774   couch potato           But for one lucky couch potato, it will.      0   \n",
              "1115  swimming pool  To ascertain that such a situation doesn’t ari...      1   \n",
              "\n",
              "                                                   text  \n",
              "2497  academy awardCloris Leachman, who won eight Em...  \n",
              "3994  café colonialAlguns ficaram dentro do imóvel, ...  \n",
              "0     double dutchThere are several theories behind ...  \n",
              "2774  couch potatoBut for one lucky couch potato, it...  \n",
              "1115  swimming poolTo ascertain that such a situatio...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9984119-27fb-489a-8037-f484c3127400\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MWE</th>\n",
              "      <th>Target</th>\n",
              "      <th>Label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>academy award</td>\n",
              "      <td>Cloris Leachman, who won eight Emmy Awards and...</td>\n",
              "      <td>1</td>\n",
              "      <td>academy awardCloris Leachman, who won eight Em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3994</th>\n",
              "      <td>café colonial</td>\n",
              "      <td>Alguns ficaram dentro do imóvel, outros do lad...</td>\n",
              "      <td>0</td>\n",
              "      <td>café colonialAlguns ficaram dentro do imóvel, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>double dutch</td>\n",
              "      <td>There are several theories behind the origin o...</td>\n",
              "      <td>0</td>\n",
              "      <td>double dutchThere are several theories behind ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>couch potato</td>\n",
              "      <td>But for one lucky couch potato, it will.</td>\n",
              "      <td>0</td>\n",
              "      <td>couch potatoBut for one lucky couch potato, it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>swimming pool</td>\n",
              "      <td>To ascertain that such a situation doesn’t ari...</td>\n",
              "      <td>1</td>\n",
              "      <td>swimming poolTo ascertain that such a situatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9984119-27fb-489a-8037-f484c3127400')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9984119-27fb-489a-8037-f484c3127400 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9984119-27fb-489a-8037-f484c3127400');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv6jBYfxeczg"
      },
      "outputs": [],
      "source": [
        "columns = ['MWE', 'Target']\n",
        "data.drop(columns, inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpHsFuVJezi3"
      },
      "outputs": [],
      "source": [
        "df = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "LXQ0qjpCenzF",
        "outputId": "c487ba6b-7f59-4a02-c209-59f589da5788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               text\n",
              "2497      1  academy awardCloris Leachman, who won eight Em...\n",
              "3994      0  café colonialAlguns ficaram dentro do imóvel, ...\n",
              "0         0  double dutchThere are several theories behind ...\n",
              "2774      0  couch potatoBut for one lucky couch potato, it...\n",
              "1115      1  swimming poolTo ascertain that such a situatio..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb5739f1-3864-4231-9974-53409f575660\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>1</td>\n",
              "      <td>academy awardCloris Leachman, who won eight Em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3994</th>\n",
              "      <td>0</td>\n",
              "      <td>café colonialAlguns ficaram dentro do imóvel, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>double dutchThere are several theories behind ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>0</td>\n",
              "      <td>couch potatoBut for one lucky couch potato, it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>1</td>\n",
              "      <td>swimming poolTo ascertain that such a situatio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb5739f1-3864-4231-9974-53409f575660')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb5739f1-3864-4231-9974-53409f575660 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb5739f1-3864-4231-9974-53409f575660');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7O90LWAn5af",
        "outputId": "6c4000e4-96d8-45a3-cc2f-42818471079f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2535\n",
              "1    1956\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "df['Label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-cswncZfS-I"
      },
      "source": [
        "We can see that all the datasets have almost equal distribution of idiom (1) and literal (0) categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "chcjdtV9VxgO",
        "outputId": "229c099c-f9d3-4a4a-a8db-7721f487f815"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAGbCAYAAAARGU4hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASkklEQVR4nO3df6jl913n8dd7M/UHKpukGYeQpDvddUCyoLEMacT+ES2bJo2YLkhpUTuUwPhHChUUGf0nWinEP7RuWTeQ3Q5NF203qLXBBOsQC939ozUTzaZJa8lYE5IhzYxOjUqhEve9f9zv6GEy0/l13/dXHw+4nO/5fL/n3M/lA3ee8/2ec251dwAAmPNvNnsCAAA7neACABgmuAAAhgkuAIBhggsAYNiuzZ7AN3PNNdf03r17N3saAADn9cQTT/xNd+8+274tHVx79+7N0aNHN3saAADnVVXPn2ufS4oAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADNu12ROAs9l76JHNngJn8dx9d272FAC2JWe4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYecNrqq6oao+U1VfrKpnqur9y/jVVXWkqp5dbq9axquqPlxVx6rqqap608pzHViOf7aqDsz9WAAAW8eFnOF6NcnPd/eNSW5Jck9V3ZjkUJLHuntfkseW+0lyR5J9y9fBJPcna4GW5N4kb05yc5J7T0caAMBOdt7g6u6XuvvPl+1/SPKlJNcluSvJg8thDyZ5x7J9V5KP9ZrPJbmyqq5N8rYkR7r7VHd/LcmRJLev608DALAFXdRruKpqb5IfSvL5JHu6+6Vl11eT7Fm2r0vywsrDXlzGzjV+5vc4WFVHq+royZMnL2Z6AABb0gUHV1V9d5LfT/Jz3f33q/u6u5P0ekyoux/o7v3dvX/37t3r8ZQAAJvqgoKrql6Xtdj6ne7+g2X45eVSYZbbE8v48SQ3rDz8+mXsXOMAADvahbxLsZJ8JMmXuvs3V3Y9nOT0Ow0PJPnUyvh7lncr3pLkleXS46eT3FZVVy0vlr9tGQMA2NF2XcAxP5LkZ5J8oaqeXMZ+Ocl9SR6qqruTPJ/kncu+R5O8PcmxJF9P8t4k6e5TVfVrSR5fjvtAd59al58CAGALO29wdff/SVLn2P3WsxzfSe45x3MdTnL4YiYIALDd+aR5AIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhp03uKrqcFWdqKqnV8Z+paqOV9WTy9fbV/b9UlUdq6ovV9XbVsZvX8aOVdWh9f9RAAC2pgs5w/XRJLefZfxD3X3T8vVoklTVjUneleQ/Lo/5b1V1RVVdkeS3k9yR5MYk716OBQDY8Xad74Du/mxV7b3A57srySe6+xtJ/rqqjiW5edl3rLu/kiRV9Ynl2C9e9IwBALaZy3kN1/uq6qnlkuNVy9h1SV5YOebFZexc469RVQer6mhVHT158uRlTA8AYGu41OC6P8l/SHJTkpeS/MZ6Tai7H+ju/d29f/fu3ev1tAAAm+a8lxTPprtfPr1dVf89yR8td48nuWHl0OuXsXyTcQCAHe2SznBV1bUrd/9zktPvYHw4ybuq6tur6o1J9iX5sySPJ9lXVW+sqm/L2gvrH770aQMAbB/nPcNVVR9PcmuSa6rqxST3Jrm1qm5K0kmeS/KzSdLdz1TVQ1l7MfyrSe7p7n9enud9ST6d5Iokh7v7mXX/aQAAtqALeZfiu88y/JFvcvwHk3zwLOOPJnn0omYHALAD+KR5AIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGLZrsyewFew99MhmTwEA2MGc4QIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBg2HmDq6oOV9WJqnp6ZezqqjpSVc8ut1ct41VVH66qY1X1VFW9aeUxB5bjn62qAzM/DgDA1nMhZ7g+muT2M8YOJXmsu/cleWy5nyR3JNm3fB1Mcn+yFmhJ7k3y5iQ3J7n3dKQBAOx05w2u7v5sklNnDN+V5MFl+8Ek71gZ/1iv+VySK6vq2iRvS3Kku09199eSHMlrIw4AYEe61Ndw7enul5btrybZs2xfl+SFleNeXMbONf4aVXWwqo5W1dGTJ09e4vQAALaOy37RfHd3kl6HuZx+vge6e39379+9e/d6PS0AwKa51OB6eblUmOX2xDJ+PMkNK8ddv4ydaxwAYMe71OB6OMnpdxoeSPKplfH3LO9WvCXJK8ulx08nua2qrlpeLH/bMgYAsOPtOt8BVfXxJLcmuaaqXszauw3vS/JQVd2d5Pkk71wOfzTJ25McS/L1JO9Nku4+VVW/luTx5bgPdPeZL8QHANiRzhtc3f3uc+x661mO7ST3nON5Dic5fFGzAwDYAXzSPADAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAMMEFADBMcAEADBNcAADDBBcAwDDBBQAwTHABAAzbtdkTALaPvYce2ewpcIbn7rtzs6cAXABnuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYdlnBVVXPVdUXqurJqjq6jF1dVUeq6tnl9qplvKrqw1V1rKqeqqo3rccPAACw1a3HGa4f7e6bunv/cv9Qkse6e1+Sx5b7SXJHkn3L18Ek96/D9wYA2PImLineleTBZfvBJO9YGf9Yr/lckiur6tqB7w8AsKVcbnB1kj+pqieq6uAytqe7X1q2v5pkz7J9XZIXVh774jIGALCj7brMx7+lu49X1fcmOVJVf7m6s7u7qvpinnAJt4NJ8oY3vOEypwcAsPku6wxXdx9fbk8k+WSSm5O8fPpS4XJ7Yjn8eJIbVh5+/TJ25nM+0N37u3v/7t27L2d6AABbwiUHV1V9V1V9z+ntJLcleTrJw0kOLIcdSPKpZfvhJO9Z3q14S5JXVi49AgDsWJdzSXFPkk9W1enn+d3u/uOqejzJQ1V1d5Lnk7xzOf7RJG9PcizJ15O89zK+NwDAtnHJwdXdX0nyg2cZ/9skbz3LeCe551K/HwDAduWT5gEAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABi2a7MnAMCl23vokc2eAmfx3H13bvYU2GKc4QIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYJrgAAIYJLgCAYYILAGCY4AIAGCa4AACGCS4AgGGCCwBgmOACABgmuAAAhgkuAIBhggsAYJjgAgAYtmuzJwAAO83eQ49s9hQ4w3P33bmp398ZLgCAYYILAGDYhgdXVd1eVV+uqmNVdWijvz8AwEbb0OCqqiuS/HaSO5LcmOTdVXXjRs4BAGCjbfQZrpuTHOvur3T3PyX5RJK7NngOAAAbaqPfpXhdkhdW7r+Y5M2rB1TVwSQHl7v/WFVf3qC5cfGuSfI3mz0JLom1256s2/Zl7TZZ/folPexi1+3fnWvHlvtYiO5+IMkDmz0Pzq+qjnb3/s2eBxfP2m1P1m37snbb03qu20ZfUjye5IaV+9cvYwAAO9ZGB9fjSfZV1Rur6tuSvCvJwxs8BwCADbWhlxS7+9Wqel+STye5Isnh7n5mI+fAunLpd/uydtuTddu+rN32tG7rVt29Xs8FAMBZ+KR5AIBhggsAYJjg4pyq6nBVnaiqp1fGrq6qI1X17HJ71TJeVfXh5U82PVVVb9q8mX9rq6obquozVfXFqnqmqt6/jFu7La6qvqOq/qyq/u+ydr+6jL+xqj6/rNH/Wt50lKr69uX+sWX/3s2c/7e6qrqiqv6iqv5ouW/dtoGqeq6qvlBVT1bV0WVs3X9fCi6+mY8muf2MsUNJHuvufUkeW+4na3+uad/ydTDJ/Rs0R17r1SQ/3903JrklyT3Ln9CydlvfN5L8WHf/YJKbktxeVbck+fUkH+ru70vytSR3L8ffneRry/iHluPYPO9P8qWV+9Zt+/jR7r5p5TO31v33peDinLr7s0lOnTF8V5IHl+0Hk7xjZfxjveZzSa6sqms3Zqas6u6XuvvPl+1/yNo/ANfF2m15yxr843L3dctXJ/mxJL+3jJ+5dqfX9PeSvLWqaoOmy4qquj7JnUn+x3K/Yt22s3X/fSm4uFh7uvulZfurSfYs22f7s03XbeTEeK3lUsUPJfl8rN22sFyWejLJiSRHkvxVkr/r7leXQ1bX51/Wbtn/SpLXb+yMWfxWkl9M8v+W+6+PddsuOsmfVNUTy58XTAZ+X265P+3D9tHdXVU+V2SLqqrvTvL7SX6uu/9+9T/Q1m7r6u5/TnJTVV2Z5JNJvn+Tp8R5VNWPJznR3U9U1a2bPR8u2lu6+3hVfW+SI1X1l6s71+v3pTNcXKyXT58+XW5PLOP+bNMWUlWvy1ps/U53/8EybO22ke7+uySfSfLDWbtscfo/yKvr8y9rt+z/t0n+doOnSvIjSX6iqp5L8omsXUr8L7Fu20J3H19uT2TtPzk3Z+D3peDiYj2c5MCyfSDJp1bG37O8g+OWJK+snI5lAy2vBflIki9192+u7LJ2W1xV7V7ObKWqvjPJf8raa/A+k+Qnl8POXLvTa/qTSf60fZr1huvuX+ru67t7b9b+ZN2fdvdPxbpteVX1XVX1Pae3k9yW5OkM/L70SfOcU1V9PMmtSa5J8nKSe5P8YZKHkrwhyfNJ3tndp5Z/5P9r1t7V+PUk7+3uo5sx7291VfWWJP87yRfyr68n+eWsvY7L2m1hVfUDWXuB7hVZ+w/xQ939gar691k7c3J1kr9I8tPd/Y2q+o4k/zNrr9M7leRd3f2VzZk9SbJcUvyF7v5x67b1LWv0yeXuriS/290frKrXZ51/XwouAIBhLikCAAwTXAAAwwQXAMAwwQUAMExwAQAME1wAAMMEFwDAsP8Pd6sUZjsnSoUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Analyzing length of sentences in training data to decide on MAX_LENGTH variable, which is required for BERT and RoBERTa\n",
        "\n",
        "sent_len = []\n",
        "for sent in df['text']:\n",
        "  sent_len.append(len(sent))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.boxplot(sent_len)\n",
        "plt.show()\n",
        "\n",
        "sent_len = [i for i in sent_len if i<=500] #Excluding the outliers\n",
        "fig2 = plt.figure(figsize =(10, 7))\n",
        "plt.hist(sent_len, 5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_65b7HJ1G7E"
      },
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Dy63oiyuZxj",
        "outputId": "69b31e5e-5046-48de-d249-d30aa2122b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "import gensim \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV349Y6QTtD0"
      },
      "outputs": [],
      "source": [
        "y = df[\"Label\"].values\n",
        "#Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\n",
        "X = []\n",
        "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "for par in df[\"text\"].values:\n",
        "    tmp = []\n",
        "    sentences = nltk.sent_tokenize(par)\n",
        "    for sent in sentences:\n",
        "        sent = sent.lower()\n",
        "        tokens = tokenizer.tokenize(sent)\n",
        "        filtered_words = [w.strip() for w in tokens if w not in stop_words and len(w) > 1]\n",
        "        tmp.extend(filtered_words)\n",
        "    X.append(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDz6ftlRTubf",
        "outputId": "079ede14-76a2-4b8e-b8eb-0f9b2117d212"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['academy',\n",
              "  'awardcloris',\n",
              "  'leachman',\n",
              "  'eight',\n",
              "  'emmy',\n",
              "  'awards',\n",
              "  'academy',\n",
              "  'award',\n",
              "  'career',\n",
              "  'spanned',\n",
              "  'nine',\n",
              "  'decades',\n",
              "  'passed',\n",
              "  'away',\n",
              "  'age']]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "X[:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pGW_RV9UAd2",
        "outputId": "31adc78b-3f6b-47c7-81d3-6422e7349a62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "y[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp2bB1I6PTl5"
      },
      "outputs": [],
      "source": [
        "X = df[\"text\"]\n",
        "y = df[\"Label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmyOmO4RlpHj"
      },
      "source": [
        "#T5 Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i_t9YgONJvm"
      },
      "source": [
        "##Installing necessary libraries for T5 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij89wdyyrRBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd418a8c-07cd-430a-e282-7381e2228993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-tanu9tjv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-tanu9tjv\n",
            "  Resolved https://github.com/huggingface/transformers to commit c749bd405e94f7eb702f82d4706fc069de928d8e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (0.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.27.0.dev0) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers==4.27.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.27.0.dev0) (2.10)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6335189 sha256=afe8871ad868935573f33a0464985f263fef8bae37c270648dcadf212d3f4203\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6kxcwcv9/wheels/42/68/45/c63edff61c292f2dfd4df4ef6522dcbecc603e7af82813c1d7\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.26.0\n",
            "    Uninstalling transformers-4.26.0:\n",
            "      Successfully uninstalled transformers-4.26.0\n",
            "Successfully installed transformers-4.27.0.dev0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "\u001b[31mERROR: Invalid requirement: 'transformers[sentencepiece]import'\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.4.0)\n",
            "Collecting lightning-utilities>=0.4.2\n",
            "  Downloading lightning_utilities-0.6.0.post0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.13.1+cu116)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.25.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.1->pytorch_lightning) (3.0.9)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n",
            "Installing collected packages: torchmetrics, lightning-utilities, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.6.0.post0 pytorch_lightning-1.9.0 torchmetrics-0.11.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install git+https://github.com/huggingface/transformers \n",
        "\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "\n",
        "!pip install sentencepiece \n",
        "!pip install datsets transformers[sentencepiece]import sentencepiece as spm \n",
        "!pip install pytorch_lightning \n",
        "import pytorch_lightning as pl\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "from transformers.utils import check_min_version\n",
        "from transformers.trainer_utils import get_last_checkpoint, is_main_process \n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b9k3O5_hG0m"
      },
      "outputs": [],
      "source": [
        "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
        "check_min_version(\"4.6.0.dev0\")\n",
        "\n",
        "task_to_keys = {\n",
        "    \"cola\": (\"sentence\", None),\n",
        "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
        "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
        "    \"qnli\": (\"question\", \"sentence\"),\n",
        "    \"qqp\": (\"question1\", \"question2\"),\n",
        "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
        "    \"sst2\": (\"sentence\", None),\n",
        "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
        "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
        "}\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpmEUg0MRq4V"
      },
      "source": [
        "##Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdoMnInKCjqG"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5Model\n",
        "from transformers import AutoModel, AutoTokenizer \n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQNsfCK1gP5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c5f630851d7e414cb97e62e4fff95a67",
            "cf6db257a50c4f54be8f174616588536",
            "f7f8902dd35d40fb82bf7afe6b6d793e",
            "084367f7beb040318d607eff4688eeca",
            "bff49bf6394b4bd3a3fdef6d4873f513",
            "aa3950f6e71a48c2bac037c222db1582",
            "7424354bd39d4e948cf77b9facd00918",
            "702f7ab8d2e8417d8eadd86bff700038",
            "f04ec388b3874708b1b3e462f7d09eb7",
            "cedf34669e81403aa8db6dddcedfbb75",
            "6409829ca3b946f0acf76bf0268b634c",
            "fd0f493f8fa24beb868785764ddea856",
            "0d485028504f4e6c8c1f486c7fbe8a57",
            "8847578b0662453489c44f0a4b2a7fbb",
            "0829236e720a4688918760ec2b8993f9",
            "cef7ad292a5446fc8a7daeccdd9ecbd5",
            "d144ee990c974a5189454539ada33e13",
            "8b001146d872443fa24d45b51992215b",
            "4f9b714c1a8f4984b42ed10f1d6dd7e8",
            "491f8dcbffab42828ed086673b708c13",
            "62307e81ce994cb0bf402390d2290910",
            "c2c8bbf83fbb47589fa62a0abef1a44a",
            "4eb495ac4e39438b9a516ff082d28241",
            "e452ecc255f7456886053918a04684b5",
            "dea68cf669a34dd69f870bcbce60bc8b",
            "95d08382a95043efb15de19f65816903",
            "13d6e0be440f4da5bbaa3cd14f69d49a",
            "ddf69a45c61242f3a10b54632b6cf208",
            "95b29799d82443a5b46262e90ad25acf",
            "6fdea6a0b58747719ced3558719c5209",
            "d452ec234ec84cb3bd496490fc41813a",
            "5f03c888e2a64b948afb0dae235bdbd4",
            "af2a32e43cc549a1a5a8d3f4dbf1a593",
            "fec348c975b44dc5b9804b8c01c297f0",
            "16bd2fef57184ff291c18abbca140fda",
            "ba0c2956ebc34b82b73e7aff26e36823",
            "bed3d6f720a54239b334784d5ab1ddb3",
            "3275aac93bb34e128304be1bd0dc75ca",
            "28872cca5d6b4524b4a3d263b1046a35",
            "4edb450cf81e4437973716e955a551d6",
            "c7e14ed379f24c419b5ec270456624a3",
            "69f10ef2a9374ad29cd1778a09049717",
            "9dc5d548f50641c8b1e3f5f73a58eec3",
            "fc4f4fe2bff340718e3278522ad1a9f1"
          ]
        },
        "outputId": "3b586083-bda9-4fb2-8bb4-564989efeb67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5f630851d7e414cb97e62e4fff95a67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd0f493f8fa24beb868785764ddea856"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eb495ac4e39438b9a516ff082d28241"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fec348c975b44dc5b9804b8c01c297f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Loading T5 base model \n",
        "\n",
        "model_name = \"t5-small\"\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "t5_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uod5vW22CJrg"
      },
      "source": [
        "Demonstrating how t5 tokenizers work on a sample sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4imEqmgk0jC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c4a3e7d-4ef8-4eaf-83d9-29f0d39d0016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  double dutchThere are several theories behind the origin of the term “Double Dutch.”\n",
            "Tokenized T5:  ['▁double', '▁du', 't', 'ch', 'There', '▁are', '▁several', '▁theories', '▁behind', '▁the', '▁origin', '▁of', '▁the', '▁term', '▁“', 'Do', 'u', 'ble', '▁Dutch', '.”']\n"
          ]
        }
      ],
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', df[\"text\"][0])\n",
        "\n",
        "# Split the sentence into tokens - T5\n",
        "print('Tokenized T5: ', t5_tokenizer.tokenize(df[\"text\"][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3C7Uj4JoO7-"
      },
      "outputs": [],
      "source": [
        "#assigning text and class to separate variables\n",
        "text = df[\"text\"].values\n",
        "labels = df[\"Label\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBemGnDPoUj_"
      },
      "outputs": [],
      "source": [
        "# Below function performs tokenization process as required by t5 model, for a given dataset\n",
        "def t5_tokenization(dataset):\n",
        "  sentences = dataset[\"text\"].values\n",
        "  labels = dataset[\"Label\"].values\n",
        "  max_length = 512\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  t5_input_ids = []\n",
        "  t5_attention_masks = []\n",
        "\n",
        "  sentence_ids = []\n",
        "  counter = 0\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      #encode_plus function will encode the sentences as required by themodel, including tokenization process and mapping token ids\n",
        "      t5_encoded_dict = t5_tokenizer.encode_plus (\n",
        "                          str(sent),        #sentence              \n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                          max_length = 512,     #Since we have seen from our analysis that majority of sentences have length less than 300.    \n",
        "                          pad_to_max_length = True,    # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                          return_attention_mask = True,   # Create attention mask\n",
        "                          truncation = True,  # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "    \n",
        "      # Add the encoded sentence to the list.    \n",
        "      t5_input_ids.append(t5_encoded_dict['input_ids'])\n",
        "      \n",
        "      # Add attention mask to the list \n",
        "      t5_attention_masks.append(t5_encoded_dict['attention_mask'])\n",
        "      \n",
        "      \n",
        "      # collecting sentence_ids\n",
        "      sentence_ids.append(counter)\n",
        "      counter  = counter + 1\n",
        "      \n",
        "      \n",
        "  # Convert the lists into tensors.\n",
        "  t5_input_ids = torch.cat(t5_input_ids, dim=0)\n",
        "  t5_attention_masks = torch.cat(t5_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "  labels = torch.tensor(labels)\n",
        "  sentence_ids = torch.tensor(sentence_ids)\n",
        "\n",
        "  return {\"T5\":[t5_input_ids, t5_attention_masks, labels]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P0lTkNRoUuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6a2df5-7b60-4383-a97f-9854b4d99be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2343: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# function to seed the script globally\n",
        "torch.manual_seed(0)\n",
        "\n",
        "#tokenizing train set\n",
        "token_dict_train = t5_tokenization(df)\n",
        "\n",
        "t5_input_ids,t5_attention_masks,labels = token_dict_train[\"T5\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXvLaMYCsdmu"
      },
      "outputs": [],
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "t5_train_dataset = TensorDataset( t5_input_ids,t5_attention_masks, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm0HkXCC7bb7"
      },
      "outputs": [],
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "t5_train_dataset = TensorDataset( t5_input_ids, t5_attention_masks, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbEli9DYGRsD"
      },
      "outputs": [],
      "source": [
        "#Create a 90-10 train-validation split\n",
        "train_size = int(0.9 * len(t5_train_dataset))\n",
        "val_size = len(t5_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(t5_train_dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23C-uPe6Imtj"
      },
      "outputs": [],
      "source": [
        "# Create data loaders for the train and validation sets\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMEW9rIVIrip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc9cb35-216f-441b-e0ae-8c1d9da5f237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the T5 model and the trainer\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "t5_model.cuda()\n",
        "\n",
        "# Create an instance of the trainer\n",
        "optimizer = AdamW(t5_model.parameters(), lr=2e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIcLev28I9MR"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH0PMUQnPOut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "outputId": "fc3b7617-3b47-4076-85ad-a9e02fe2e0c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-43528c6338e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Get the logits from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Get the logits from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_attention_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1626\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1627\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 )\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1056\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    688\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     ):\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         attention_output = self.SelfAttention(\n\u001b[1;32m    594\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.76 GiB total capacity; 13.76 GiB already allocated; 9.88 MiB free; 13.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "#training with more than one epoch\n",
        "# Number of training epochs (passes through the dataset)\n",
        "num_epochs = 2\n",
        "\n",
        "# Track the training loss and accuracy\n",
        "train_loss_set = []\n",
        "train_acc_set = []\n",
        "\n",
        "# Start training\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Unpack the batch\n",
        "        b_input_ids, b_attention_masks, b_labels = batch\n",
        "\n",
        "        # Move the inputs and labels to the GPU\n",
        "        b_input_ids = b_input_ids.to(device)\n",
        "        b_attention_masks = b_attention_masks.to(device)\n",
        "        b_labels = b_labels.to(device)\n",
        "\n",
        "        # Zero-out the gradients from previous iteration\n",
        "        t5_model.zero_grad()\n",
        "\n",
        "        # Get the logits from the model\n",
        "        # Get the logits from the model\n",
        "        logits = t5_model(input_ids=b_input_ids, attention_mask=b_attention_masks,decoder_input_ids=b_input_ids)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss_func = nn.CrossEntropyLoss()\n",
        "        loss = loss_func(logits.view(-1, logits.shape[-1]), b_labels.view(-1))\n",
        "\n",
        "        # Perform backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Track the training loss and f1_score\n",
        "        train_loss_set.append(loss.item())\n",
        "        train_acc_set.append(f1_score(logits, b_labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training with one epoch\n",
        "# Set the model to train mode\n",
        "t5_model.train()\n",
        "\n",
        "# Loop over the data\n",
        "for input_ids, attention_masks, labels in train_dataloader:\n",
        "    # Move the input and labels to the GPU\n",
        "    input_ids = input_ids.to('cuda')\n",
        "    attention_masks = attention_masks.to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Perform a forward pass\n",
        "    outputs = t5_model(input_ids=input_ids, attention_mask=attention_masks, labels=labels)\n",
        "    loss = outputs[0]\n",
        "\n",
        "    # Perform backpropagation and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "YuTZD1wac_Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP-Ol7hfoC8a"
      },
      "source": [
        "# Zero Shot Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-GiQvnkoL67"
      },
      "source": [
        "## Train Zero shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKrtUxtxV4ZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d6816a-3692-431e-ef98-d4857e816289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/ZeroShot/0/runs/Jan30_11-28-59_619f04e19078,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=f1,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=models/ZeroShot/0/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/ZeroShot/0/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=0,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "INFO:__main__:load a local file for train: Data/ZeroShot/train.csv\n",
            "INFO:__main__:load a local file for validation: Data/ZeroShot/dev.csv\n",
            "WARNING:datasets.builder:Using custom data configuration default-3b178a6fa6c41771\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-3b178a6fa6c41771/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n",
            "Downloading data files: 100% 2/2 [00:00<00:00, 7717.21it/s]\n",
            "Extracting data files: 100% 2/2 [00:00<00:00, 2023.79it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-3b178a6fa6c41771/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 913.69it/s]\n",
            "[INFO|configuration_utils.py:664] 2023-01-30 11:29:00,836 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/config.json\n",
            "[INFO|configuration_utils.py:716] 2023-01-30 11:29:00,839 >> Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.27.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:459] 2023-01-30 11:29:01,198 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:664] 2023-01-30 11:29:01,554 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/config.json\n",
            "[INFO|configuration_utils.py:716] 2023-01-30 11:29:01,555 >> Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.27.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 2.69MB/s]\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-01-30 11:29:03,525 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/spiece.model\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-01-30 11:29:03,525 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-01-30 11:29:03,525 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-01-30 11:29:03,525 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1802] 2023-01-30 11:29:03,525 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:664] 2023-01-30 11:29:03,525 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/3479082dc36f8a4730936ef1c9b88cd8b0835c53/config.json\n",
            "[INFO|configuration_utils.py:716] 2023-01-30 11:29:03,526 >> Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.27.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py\", line 537, in <module>\n",
            "    main()\n",
            "  File \"/content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py\", line 315, in main\n",
            "    model = AutoModelForSequenceClassification.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\", line 467, in from_pretrained\n",
            "    raise ValueError(\n",
            "ValueError: Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForSequenceClassification.\n",
            "Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BloomConfig, CamembertConfig, CanineConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, EsmConfig, FlaubertConfig, FNetConfig, FunnelConfig, GPT2Config, GPT2Config, GPTNeoConfig, GPTJConfig, IBertConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegatronBertConfig, MobileBertConfig, MPNetConfig, MvpConfig, NezhaConfig, NystromformerConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PLBartConfig, QDQBertConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, TapasConfig, TransfoXLConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, YosoConfig.\n"
          ]
        }
      ],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "        --model_name_or_path 't5-small' \\\n",
        "        --do_train \\\n",
        "        --do_eval \\\n",
        "        --max_seq_length 128 \\\n",
        "        --per_device_train_batch_size 32 \\\n",
        "        --learning_rate 2e-5 \\\n",
        "        --num_train_epochs 9 \\\n",
        "        --evaluation_strategy \"epoch\" \\\n",
        "        --output_dir models/ZeroShot/0/ \\\n",
        "        --seed 0 \\\n",
        "        --train_file      Data/ZeroShot/train.csv \\\n",
        "        --validation_file Data/ZeroShot/dev.csv \\\n",
        "        --evaluation_strategy \"epoch\" \\\n",
        "        --save_strategy \"epoch\"  \\\n",
        "        --load_best_model_at_end \\\n",
        "        --metric_for_best_model \"f1\" \\\n",
        "        --save_total_limit 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrfwDiORPDyS",
        "outputId": "3e5d3939-fb25-4fda-f01c-c296ff855330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibb2Uo0vPPc3"
      },
      "outputs": [],
      "source": [
        "## Create save path\n",
        "!mkdir -p /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/\n",
        "## Copy saved model.\n",
        "!cp -r /content/models/ZeroShot/0/* /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etL-Ic6bPmtA"
      },
      "outputs": [],
      "source": [
        "## Bring back saved model here. \n",
        "#!mkdir -p /content/models/ZeroShot/0/\n",
        "# !cp -r /content/gdrive/MyDrive/ColabData/SemEval2022Task2/TaskA/ZeroShot/0/* /content/models/ZeroShot/0/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bN4iUHWP45b"
      },
      "source": [
        "## Evaluation On Dev Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houOZpcYO-Pw",
        "outputId": "481e29c4-2979-4cb5-c59f-cdeec9f55e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=epoch,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=passive,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/ZeroShot/0/eval-dev/runs/Jan22_10-27-07_b46fcfbf13d0,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=f1,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=models/ZeroShot/0/eval-dev/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/ZeroShot/0/eval-dev/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=1,\n",
            "seed=0,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "INFO:__main__:load a local file for train: Data/ZeroShot/train.csv\n",
            "INFO:__main__:load a local file for validation: Data/ZeroShot/dev.csv\n",
            "INFO:__main__:load a local file for test: Data/ZeroShot/dev.csv\n",
            "WARNING:datasets.builder:Using custom data configuration default-76e1cb89c5a4bad3\n",
            "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-76e1cb89c5a4bad3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n",
            "Downloading data files: 100% 3/3 [00:00<00:00, 15178.42it/s]\n",
            "Extracting data files: 100% 3/3 [00:00<00:00, 2295.73it/s]\n",
            "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-76e1cb89c5a4bad3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 1056.23it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 620, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/utils/hub.py\", line 409, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    validate_repo_id(arg_value)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/huggingface_hub/utils/_validators.py\", line 166, in validate_repo_id\n",
            "    raise HFValidationError(\n",
            "huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/models/ZeroShot/0'. Use `repo_type` argument if needed.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py\", line 537, in <module>\n",
            "    main()\n",
            "  File \"/content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py\", line 300, in main\n",
            "    config = AutoConfig.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/configuration_auto.py\", line 852, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 565, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\", line 641, in _get_config_dict\n",
            "    raise EnvironmentError(\n",
            "OSError: Can't load the configuration of '/content/models/ZeroShot/0'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/content/models/ZeroShot/0' is the correct path to a directory containing a config.json file\n"
          ]
        }
      ],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "        --model_name_or_path '/content/models/ZeroShot/0' \\\n",
        "        --do_predict \\\n",
        "        --max_seq_length 128 \\\n",
        "        --per_device_train_batch_size 32 \\\n",
        "        --learning_rate 2e-5 \\\n",
        "        --num_train_epochs 9 \\\n",
        "        --evaluation_strategy \"epoch\" \\\n",
        "        --output_dir models/ZeroShot/0/eval-dev/ \\\n",
        "        --seed 0 \\\n",
        "        --train_file      Data/ZeroShot/train.csv \\\n",
        "        --validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/dev.csv \\\n",
        "        --evaluation_strategy \"epoch\" \\\n",
        "        --save_strategy \"epoch\"  \\\n",
        "        --load_best_model_at_end \\\n",
        "        --metric_for_best_model \"f1\" \\\n",
        "        --save_total_limit 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHqPYuTS3muJ"
      },
      "source": [
        "### Use predictions to create the submission file (for dev data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfWUuwg7Qm-t"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/0/eval-dev/test_results_None.txt'                        ,\n",
        "    }\n",
        "params[ 'setting' ] = 'zero_shot'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgFGlGnTROJZ"
      },
      "outputs": [],
      "source": [
        " updated_data = insert_to_submission_file( **params )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXcRbv70RZfR"
      },
      "outputs": [],
      "source": [
        "!mkdir -p outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ezIzyWTRePp",
        "outputId": "7de89b60-8070-46de-b295-fa90cf847955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote outputs/zero_shot_dev_formated.csv\n"
          ]
        }
      ],
      "source": [
        "write_csv( updated_data, 'outputs/zero_shot_dev_formated.csv' ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZpFkOSQ3x_A"
      },
      "source": [
        "### For the development data, we can run evaluation script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "Dn6MyP9jRnFA",
        "outputId": "a4e5e3e6-287b-4de6-c643-e569e9c2b42e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"zero_shot\",\n\"EN\",\n0.6617513092193399],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"zero_shot\",\n\"PT\",\n0.6385562974902141],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"zero_shot\",\n\"EN,PT\",\n0.6730190553300397],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"one_shot\",\n\"EN\",\n[null, null, null]],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"one_shot\",\n\"PT\",\n[null, null, null]],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"one_shot\",\n\"EN,PT\",\n[null, null, null]]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Settings\"], [\"string\", \"Languages\"], [\"string\", \"F1 Score (Macro)\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Settings</th>\n",
              "      <th>Languages</th>\n",
              "      <th>F1 Score (Macro)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero_shot</td>\n",
              "      <td>EN</td>\n",
              "      <td>0.661751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>zero_shot</td>\n",
              "      <td>PT</td>\n",
              "      <td>0.638556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zero_shot</td>\n",
              "      <td>EN,PT</td>\n",
              "      <td>0.673019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>one_shot</td>\n",
              "      <td>EN</td>\n",
              "      <td>(None, None, None)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one_shot</td>\n",
              "      <td>PT</td>\n",
              "      <td>(None, None, None)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>one_shot</td>\n",
              "      <td>EN,PT</td>\n",
              "      <td>(None, None, None)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Settings Languages    F1 Score (Macro)\n",
              "0  zero_shot        EN            0.661751\n",
              "1  zero_shot        PT            0.638556\n",
              "2  zero_shot     EN,PT            0.673019\n",
              "3   one_shot        EN  (None, None, None)\n",
              "4   one_shot        PT  (None, None, None)\n",
              "5   one_shot     EN,PT  (None, None, None)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append( '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/' ) \n",
        "from SubTask1Evaluator import evaluate_submission\n",
        "\n",
        "\n",
        "submission_file = 'outputs/zero_shot_dev_formated.csv'\n",
        "gold_file       = '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/dev_gold.csv'\n",
        "\n",
        "results = evaluate_submission( submission_file, gold_file )\n",
        "%reload_ext google.colab.data_table\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data=results[1:], columns=results[0])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UX9ys7tTKVi"
      },
      "source": [
        "## Generate Eval Data output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ets4flitTRZZ",
        "outputId": "1deda94d-73b9-4955-c0d4-4999e3b306ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/03/2021 19:13:53 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "09/03/2021 19:13:53 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.EPOCH,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=models/ZeroShot/0/eval-eval/runs/Sep03_19-13-53_eb29b3e472c9,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=f1,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=9.0,\n",
            "output_dir=models/ZeroShot/0/eval-eval/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=eval-eval,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=models/ZeroShot/0/eval-eval/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=1,\n",
            "seed=0,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "09/03/2021 19:13:53 - INFO - __main__ -   load a local file for train: Data/ZeroShot/train.csv\n",
            "09/03/2021 19:13:53 - INFO - __main__ -   load a local file for validation: Data/ZeroShot/dev.csv\n",
            "09/03/2021 19:13:53 - INFO - __main__ -   load a local file for test: Data/ZeroShot/eval.csv\n",
            "09/03/2021 19:13:53 - WARNING - datasets.builder -   Using custom data configuration default-c7581e3ebff4090e\n",
            "09/03/2021 19:13:53 - WARNING - datasets.builder -   Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-c7581e3ebff4090e/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n",
            "[INFO|configuration_utils.py:559] 2021-09-03 19:13:53,583 >> loading configuration file /content/models/ZeroShot/0/config.json\n",
            "[INFO|configuration_utils.py:598] 2021-09-03 19:13:53,584 >> Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.11.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1671] 2021-09-03 19:13:53,584 >> Didn't find file /content/models/ZeroShot/0/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-03 19:13:53,585 >> loading file /content/models/ZeroShot/0/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-03 19:13:53,585 >> loading file /content/models/ZeroShot/0/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-03 19:13:53,585 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-03 19:13:53,585 >> loading file /content/models/ZeroShot/0/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1739] 2021-09-03 19:13:53,585 >> loading file /content/models/ZeroShot/0/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:1277] 2021-09-03 19:13:53,678 >> loading weights file /content/models/ZeroShot/0/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:1524] 2021-09-03 19:13:55,564 >> All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "[INFO|modeling_utils.py:1533] 2021-09-03 19:13:55,564 >> All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/models/ZeroShot/0.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "100% 5/5 [00:01<00:00,  4.88ba/s]\n",
            "100% 1/1 [00:00<00:00,  7.32ba/s]\n",
            "100% 1/1 [00:00<00:00,  6.88ba/s]\n",
            "09/03/2021 19:13:59 - INFO - __main__ -   *** Evaluate ***\n",
            "[INFO|trainer.py:521] 2021-09-03 19:13:59,991 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
            "[INFO|trainer.py:2181] 2021-09-03 19:13:59,993 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2183] 2021-09-03 19:13:59,993 >>   Num examples = 739\n",
            "[INFO|trainer.py:2186] 2021-09-03 19:13:59,993 >>   Batch size = 8\n",
            "100% 93/93 [00:03<00:00, 27.86it/s]\n",
            "***** eval metrics *****\n",
            "  eval_accuracy           =     0.6739\n",
            "  eval_f1                 =      0.673\n",
            "  eval_loss               =     2.0822\n",
            "  eval_runtime            = 0:00:03.38\n",
            "  eval_samples            =        739\n",
            "  eval_samples_per_second =    218.476\n",
            "  eval_steps_per_second   =     27.494\n",
            "09/03/2021 19:14:03 - INFO - __main__ -   *** Test ***\n",
            "/content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py:514: FutureWarning: remove_columns_ is deprecated and will be removed in the next major version of datasets. Use Dataset.remove_columns instead.\n",
            "  test_dataset.remove_columns_(\"label\")\n",
            "[INFO|trainer.py:521] 2021-09-03 19:14:03,380 >> The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence1.\n",
            "[INFO|trainer.py:2181] 2021-09-03 19:14:03,382 >> ***** Running Prediction *****\n",
            "[INFO|trainer.py:2183] 2021-09-03 19:14:03,382 >>   Num examples = 762\n",
            "[INFO|trainer.py:2186] 2021-09-03 19:14:03,382 >>   Batch size = 8\n",
            " 97% 93/96 [00:03<00:00, 27.70it/s]09/03/2021 19:14:06 - INFO - __main__ -   ***** Test results None *****\n",
            "100% 96/96 [00:03<00:00, 27.20it/s]\n"
          ]
        }
      ],
      "source": [
        "!python /content/AStitchInLanguageModels/Dataset/Task2/Utils/run_glue_f1_macro.py \\\n",
        "    \t--model_name_or_path '/content/models/ZeroShot/0' \\\n",
        "    \t--do_predict \\\n",
        "    \t--max_seq_length 128 \\\n",
        "    \t--per_device_train_batch_size 32 \\\n",
        "    \t--learning_rate 2e-5 \\\n",
        "    \t--num_train_epochs 9 \\\n",
        "    \t--evaluation_strategy \"epoch\" \\\n",
        "    \t--output_dir models/ZeroShot/0/eval-eval/ \\\n",
        "    \t--seed 0 \\\n",
        "    \t--train_file      Data/ZeroShot/train.csv \\\n",
        "    \t--validation_file Data/ZeroShot/dev.csv \\\n",
        "      --test_file Data/ZeroShot/eval.csv \\\n",
        "\t    --evaluation_strategy \"epoch\" \\\n",
        "\t    --save_strategy \"epoch\"  \\\n",
        "\t    --load_best_model_at_end \\\n",
        "\t    --metric_for_best_model \"f1\" \\\n",
        "\t    --save_total_limit 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSS6PFfb4AAl"
      },
      "source": [
        "### Use predictions to create the submission file (for eval data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqxzrRBfTcnq"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'submission_format_file' : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval_submission_format.csv' ,\n",
        "    'input_file'             : '/content/SemEval_2022_Task2-idiomaticity/SubTaskA/Data/eval.csv'                   ,\n",
        "    'prediction_format_file' : '/content/models/ZeroShot/0/eval-eval/test_results_None.txt'                        ,\n",
        "    }\n",
        "params[ 'setting' ] = 'zero_shot'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHqanuVDTz-r"
      },
      "outputs": [],
      "source": [
        " updated_data = insert_to_submission_file( **params )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKDBuxMLT5QU",
        "outputId": "f5eefcfb-ace6-4225-f64a-92bba8dd3ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote outputs/zero_shot_eval_formated.csv\n"
          ]
        }
      ],
      "source": [
        "write_csv( updated_data, 'outputs/zero_shot_eval_formated.csv' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyWXLvHI4Cdt"
      },
      "source": [
        "**NOTE**: You can submit this file, but it only has results for the zero-shot setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLz_mxylfc1e"
      },
      "source": [
        "# Download Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "R6vl3zemfeg6",
        "outputId": "b9519c6b-2fd9-49b6-c582-75dfbb9dfd8b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0b2add23-bf84-401b-a865-112570e325ba\", \"task2_subtaska.csv\", 32621)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/outputs/task2_subtaska.csv') \n",
        "## Remeber to put this in a folder called \"submission\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuNKaVgbf2a2"
      },
      "source": [
        "# Discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "cd78IDfLf3Xy",
        "outputId": "585f4392-9f86-4733-f06d-7b56382a0cea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"zero_shot\",\n\"EN\",\n{\n            'v': 0.6617513092193399,\n            'f': \"0.6617513092193399\",\n        }],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"zero_shot\",\n\"PT\",\n{\n            'v': 0.6385562974902141,\n            'f': \"0.6385562974902141\",\n        }],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"zero_shot\",\n\"EN,PT\",\n{\n            'v': 0.6730190553300397,\n            'f': \"0.6730190553300397\",\n        }],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"one_shot\",\n\"EN\",\n{\n            'v': 0.8704885668832538,\n            'f': \"0.8704885668832538\",\n        }],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"one_shot\",\n\"PT\",\n{\n            'v': 0.8665745046290478,\n            'f': \"0.8665745046290478\",\n        }],\n [{\n            'v': 5,\n            'f': \"5\",\n        },\n\"one_shot\",\n\"EN,PT\",\n{\n            'v': 0.8738206313099324,\n            'f': \"0.8738206313099324\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Settings\"], [\"string\", \"Languages\"], [\"number\", \"F1 Score (Macro)\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Settings</th>\n",
              "      <th>Languages</th>\n",
              "      <th>F1 Score (Macro)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zero_shot</td>\n",
              "      <td>EN</td>\n",
              "      <td>0.661751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>zero_shot</td>\n",
              "      <td>PT</td>\n",
              "      <td>0.638556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>zero_shot</td>\n",
              "      <td>EN,PT</td>\n",
              "      <td>0.673019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>one_shot</td>\n",
              "      <td>EN</td>\n",
              "      <td>0.870489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one_shot</td>\n",
              "      <td>PT</td>\n",
              "      <td>0.866575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>one_shot</td>\n",
              "      <td>EN,PT</td>\n",
              "      <td>0.873821</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Settings Languages  F1 Score (Macro)\n",
              "0  zero_shot        EN          0.661751\n",
              "1  zero_shot        PT          0.638556\n",
              "2  zero_shot     EN,PT          0.673019\n",
              "3   one_shot        EN          0.870489\n",
              "4   one_shot        PT          0.866575\n",
              "5   one_shot     EN,PT          0.873821"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEYD3V3I5qEN"
      },
      "source": [
        "Notice the significant jump in F1 scores with the introduction of just one positive and one negative example. \n",
        "\n",
        "Note that your position on the leaderboard will be based on rows with index 2 and 5 (combined results for both languages). The rest of the results for information and ablation studies. \n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "do-TXGBemGgH",
        "TvC8kAGNnKk_",
        "uP-Ol7hfoC8a",
        "o-GiQvnkoL67",
        "5bN4iUHWP45b",
        "EHqPYuTS3muJ",
        "rZpFkOSQ3x_A",
        "rLz_mxylfc1e",
        "EuNKaVgbf2a2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5f630851d7e414cb97e62e4fff95a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf6db257a50c4f54be8f174616588536",
              "IPY_MODEL_f7f8902dd35d40fb82bf7afe6b6d793e",
              "IPY_MODEL_084367f7beb040318d607eff4688eeca"
            ],
            "layout": "IPY_MODEL_bff49bf6394b4bd3a3fdef6d4873f513"
          }
        },
        "cf6db257a50c4f54be8f174616588536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa3950f6e71a48c2bac037c222db1582",
            "placeholder": "​",
            "style": "IPY_MODEL_7424354bd39d4e948cf77b9facd00918",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "f7f8902dd35d40fb82bf7afe6b6d793e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702f7ab8d2e8417d8eadd86bff700038",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f04ec388b3874708b1b3e462f7d09eb7",
            "value": 791656
          }
        },
        "084367f7beb040318d607eff4688eeca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cedf34669e81403aa8db6dddcedfbb75",
            "placeholder": "​",
            "style": "IPY_MODEL_6409829ca3b946f0acf76bf0268b634c",
            "value": " 792k/792k [00:00&lt;00:00, 1.75MB/s]"
          }
        },
        "bff49bf6394b4bd3a3fdef6d4873f513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa3950f6e71a48c2bac037c222db1582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7424354bd39d4e948cf77b9facd00918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "702f7ab8d2e8417d8eadd86bff700038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04ec388b3874708b1b3e462f7d09eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cedf34669e81403aa8db6dddcedfbb75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6409829ca3b946f0acf76bf0268b634c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd0f493f8fa24beb868785764ddea856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d485028504f4e6c8c1f486c7fbe8a57",
              "IPY_MODEL_8847578b0662453489c44f0a4b2a7fbb",
              "IPY_MODEL_0829236e720a4688918760ec2b8993f9"
            ],
            "layout": "IPY_MODEL_cef7ad292a5446fc8a7daeccdd9ecbd5"
          }
        },
        "0d485028504f4e6c8c1f486c7fbe8a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d144ee990c974a5189454539ada33e13",
            "placeholder": "​",
            "style": "IPY_MODEL_8b001146d872443fa24d45b51992215b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "8847578b0662453489c44f0a4b2a7fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f9b714c1a8f4984b42ed10f1d6dd7e8",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_491f8dcbffab42828ed086673b708c13",
            "value": 1206
          }
        },
        "0829236e720a4688918760ec2b8993f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62307e81ce994cb0bf402390d2290910",
            "placeholder": "​",
            "style": "IPY_MODEL_c2c8bbf83fbb47589fa62a0abef1a44a",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 58.9kB/s]"
          }
        },
        "cef7ad292a5446fc8a7daeccdd9ecbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d144ee990c974a5189454539ada33e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b001146d872443fa24d45b51992215b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f9b714c1a8f4984b42ed10f1d6dd7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491f8dcbffab42828ed086673b708c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62307e81ce994cb0bf402390d2290910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c8bbf83fbb47589fa62a0abef1a44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eb495ac4e39438b9a516ff082d28241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e452ecc255f7456886053918a04684b5",
              "IPY_MODEL_dea68cf669a34dd69f870bcbce60bc8b",
              "IPY_MODEL_95d08382a95043efb15de19f65816903"
            ],
            "layout": "IPY_MODEL_13d6e0be440f4da5bbaa3cd14f69d49a"
          }
        },
        "e452ecc255f7456886053918a04684b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf69a45c61242f3a10b54632b6cf208",
            "placeholder": "​",
            "style": "IPY_MODEL_95b29799d82443a5b46262e90ad25acf",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "dea68cf669a34dd69f870bcbce60bc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fdea6a0b58747719ced3558719c5209",
            "max": 242065649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d452ec234ec84cb3bd496490fc41813a",
            "value": 242065649
          }
        },
        "95d08382a95043efb15de19f65816903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f03c888e2a64b948afb0dae235bdbd4",
            "placeholder": "​",
            "style": "IPY_MODEL_af2a32e43cc549a1a5a8d3f4dbf1a593",
            "value": " 242M/242M [00:02&lt;00:00, 91.3MB/s]"
          }
        },
        "13d6e0be440f4da5bbaa3cd14f69d49a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf69a45c61242f3a10b54632b6cf208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b29799d82443a5b46262e90ad25acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fdea6a0b58747719ced3558719c5209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d452ec234ec84cb3bd496490fc41813a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f03c888e2a64b948afb0dae235bdbd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2a32e43cc549a1a5a8d3f4dbf1a593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fec348c975b44dc5b9804b8c01c297f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16bd2fef57184ff291c18abbca140fda",
              "IPY_MODEL_ba0c2956ebc34b82b73e7aff26e36823",
              "IPY_MODEL_bed3d6f720a54239b334784d5ab1ddb3"
            ],
            "layout": "IPY_MODEL_3275aac93bb34e128304be1bd0dc75ca"
          }
        },
        "16bd2fef57184ff291c18abbca140fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28872cca5d6b4524b4a3d263b1046a35",
            "placeholder": "​",
            "style": "IPY_MODEL_4edb450cf81e4437973716e955a551d6",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "ba0c2956ebc34b82b73e7aff26e36823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7e14ed379f24c419b5ec270456624a3",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69f10ef2a9374ad29cd1778a09049717",
            "value": 147
          }
        },
        "bed3d6f720a54239b334784d5ab1ddb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dc5d548f50641c8b1e3f5f73a58eec3",
            "placeholder": "​",
            "style": "IPY_MODEL_fc4f4fe2bff340718e3278522ad1a9f1",
            "value": " 147/147 [00:00&lt;00:00, 2.34kB/s]"
          }
        },
        "3275aac93bb34e128304be1bd0dc75ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28872cca5d6b4524b4a3d263b1046a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4edb450cf81e4437973716e955a551d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7e14ed379f24c419b5ec270456624a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69f10ef2a9374ad29cd1778a09049717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dc5d548f50641c8b1e3f5f73a58eec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4f4fe2bff340718e3278522ad1a9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}